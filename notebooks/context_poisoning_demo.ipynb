{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context Poisoning: When Errors Get Repeatedly Referenced\n",
    "\n",
    "Context poisoning occurs when a **hallucination or other error makes it into the context, where it is repeatedly referenced**.\n",
    "\n",
    "## The Problem\n",
    "\n",
    "LLM agents often maintain context about their goals, progress, and state. When an error (hallucination, incorrect assumption, or wrong information) makes it into this context, the agent doesn't just use it onceâ€”it **keeps referencing it** over and over:\n",
    "\n",
    "1. **Error enters context**: Agent hallucinates something (e.g., \"Research Quantum Dynamics Corp with ticker QDYN\")\n",
    "2. **Error gets stored**: The hallucination is saved in goals, summaries, or state\n",
    "3. **Repeated reference**: Agent repeatedly checks goals, sees the hallucinated item, and references it\n",
    "4. **Fixation**: Agent becomes stuck trying to achieve something impossible\n",
    "\n",
    "**Context Poisoning Definition:** When a hallucination or other error makes it into the context, where it is repeatedly referenced, causing the agent to make decisions based on false information.\n",
    "\n",
    "## Why This Matters\n",
    "\n",
    "As noted in the DeepMind Gemini 2.5 technical report: *\"An especially egregious form of this issue can take place with 'context poisoning'â€”where many parts of the context (goals, summary) are 'poisoned' with misinformation about the game state, which can often take a very long time to undo. As a result, the model can become fixated on achieving impossible or irrelevant goals.\"*\n",
    "\n",
    "This is a **real production problem** affecting agents that:\n",
    "- Maintain multi-turn conversations\n",
    "- Track goals or tasks over time\n",
    "- Create summaries of their progress\n",
    "- Make decisions based on accumulated context\n",
    "\n",
    "## What We'll Explore\n",
    "\n",
    "In this notebook, we'll demonstrate context poisoning with a financial research agent:\n",
    "\n",
    "1. **Inject** an error into the agent's context (a goal about researching a non-existent company)\n",
    "2. **Observe** how the agent repeatedly references this poisoned information\n",
    "3. **Measure** the impact: How many times does the agent reference the error? Does it recognize the problem?\n",
    "4. **Evaluate** recovery: Can the agent recognize impossible goals and stop pursuing them?\n",
    "\n",
    "The goal: Understand how errors poison context through repeated reference, and how to build agents that can detect and recover from poisoned context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Setup complete\n"
     ]
    }
   ],
   "source": [
    "# Check if dependencies are installed\n",
    "try:\n",
    "    import langchain\n",
    "    import langchain_anthropic\n",
    "    import langsmith\n",
    "    DEPENDENCIES_INSTALLED = True\n",
    "except ImportError as e:\n",
    "    DEPENDENCIES_INSTALLED = False\n",
    "    missing_module = str(e).split(\"'\")[1] if \"'\" in str(e) else \"unknown\"\n",
    "    print(f\"âŒ Missing dependency: {missing_module}\")\n",
    "    print(\"\\nðŸ“¦ To install dependencies, run one of the following:\")\n",
    "    print(\"   1. Using uv:  uv sync\")\n",
    "    print(\"   2. Using pip: pip install langchain langchain-anthropic langsmith langgraph\")\n",
    "    print(\"\\n   Then restart your Jupyter kernel.\")\n",
    "    raise\n",
    "\n",
    "# Standard library\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "from datetime import datetime\n",
    "\n",
    "# LangChain & LangSmith\n",
    "from langchain.agents import create_agent\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langsmith import Client, evaluate\n",
    "from langsmith.schemas import Run, Example\n",
    "\n",
    "# Visualization\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Environment\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Agent components\n",
    "from context_poisoning.tools import (\n",
    "    all_tools,\n",
    "    reset_state,\n",
    "    inject_poisoned_goal,\n",
    ")\n",
    "from context_poisoning.instructions import FINANCIAL_RESEARCH_INSTRUCTIONS\n",
    "\n",
    "# Evaluators and test data\n",
    "from context_poisoning.tests.evaluators import (\n",
    "    context_poisoning_evaluator,\n",
    "    goal_cancellation_evaluator,\n",
    "    task_completion_evaluator,\n",
    ")\n",
    "from context_poisoning.tests.setup_datasets import create_poisoning_dataset\n",
    "from context_poisoning.resources.test_cases import TEST_CASES\n",
    "\n",
    "# Agent utilities\n",
    "from context_poisoning.utils.agent_helpers import (\n",
    "    run_agent_with_trajectory,\n",
    ")\n",
    "\n",
    "# Initialize LangSmith\n",
    "client = Client()\n",
    "\n",
    "print(\"âœ“ Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: claude-haiku-4-5-20251001\n"
     ]
    }
   ],
   "source": [
    "# Initialize LLM - using Claude Haiku for context poisoning demo\n",
    "llm = ChatAnthropic(model=\"claude-haiku-4-5-20251001\", temperature=0)\n",
    "\n",
    "print(f\"Using model: {llm.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Financial Research Agent\n",
    "\n",
    "Our financial research agent helps conduct research on companies, stocks, and market sectors. The agent can:\n",
    "- Track companies and get stock prices\n",
    "- Gather company information and financial data\n",
    "- Analyze sectors and market trends\n",
    "- Set and track research goals\n",
    "- Create research summaries and notes\n",
    "- Complete research objectives\n",
    "\n",
    "**The Problem:** When the agent hallucinates information (like a non-existent company ticker, incorrect stock price, or impossible financial metric), this misinformation can make it into research summaries and goals. Once there, it gets repeatedly referenced, \"poisoning\" the context and causing the agent to pursue impossible research objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Financial research agent created\n"
     ]
    }
   ],
   "source": [
    "# Create agent\n",
    "research_agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=all_tools,\n",
    "    system_prompt=FINANCIAL_RESEARCH_INSTRUCTIONS\n",
    ")\n",
    "\n",
    "print(\"âœ“ Financial research agent created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Cases: How Errors Get Repeatedly Referenced\n",
    "\n",
    "We have 5 test cases demonstrating how different types of errors get into context and are repeatedly referenced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Loaded 5 test cases\n",
      "\n",
      "1. Non-existent Company Research\n",
      "   A hallucinated goal about researching a company that doesn't exist gets into the research goals\n",
      "   Poisoned goal: 'Research the financial performance of 'Quantum Dynamics Corp' (ticker: QDYN) and analyze its Q4 earnings'\n",
      "\n",
      "2. Hallucinated Stock Price\n",
      "   Agent hallucinates that a stock price is at a specific level when it's not\n",
      "\n",
      "3. Impossible Sector Analysis\n",
      "   Goal requires analyzing a sector that doesn't exist\n",
      "   Poisoned goal: 'Analyze the 'Quantum Computing' sector and identify the top 5 companies by market cap'\n",
      "\n",
      "4. Fictional Financial Metric\n",
      "   Agent believes it needs to find a financial metric that doesn't exist\n",
      "   Poisoned goal: 'Find the 'Quantum Revenue Index' for all S&P 500 companies and compare it across sectors'\n",
      "\n",
      "5. Circular Research Dependency\n",
      "   Goal A requires data from Goal B, but Goal B requires data from Goal A\n",
      "   Poisoned goal: 'Complete the 'Market Analysis Report' which requires first completing the 'Sector Deep Dive' (which requires the Market Analysis Report)'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"âœ“ Loaded {len(TEST_CASES)} test cases\\n\")\n",
    "\n",
    "for i, test_case in enumerate(TEST_CASES, 1):\n",
    "    print(f\"{i}. {test_case['name']}\")\n",
    "    print(f\"   {test_case['description']}\")\n",
    "    if test_case.get('poisoned_goal'):\n",
    "        print(f\"   Poisoned goal: '{test_case['poisoned_goal']}'\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset in LangSmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Deleted existing dataset: context-poisoning-evaluation\n",
      "âœ“ Created dataset with 5 examples\n",
      "   View dataset: https://smith.langchain.com/o/39ebafb1-dcf2-4667-a7f3-ce83ae540e87/datasets/c6dd8f72-28e4-439f-86bf-adbca6e549bc\n"
     ]
    }
   ],
   "source": [
    "# Create dataset in LangSmith\n",
    "dataset_name = \"context-poisoning-evaluation\"\n",
    "dataset = create_poisoning_dataset(dataset_name, TEST_CASES, client)\n",
    "\n",
    "print(f\"âœ“ Created dataset with {len(TEST_CASES)} examples\")\n",
    "print(f\"   View dataset: https://smith.langchain.com/o/{client._get_tenant_id()}/datasets/{dataset.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Evaluation Metrics\n",
    "\n",
    "We'll use three evaluators to measure context poisoning impact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Loaded 3 evaluators\n",
      "   - context_poisoning: Measures references to poisoned text, impossible goal pursuit, recovery\n",
      "   - goal_cancellation: Checks if agent recognizes and cancels impossible goals\n",
      "   - task_completion: Measures if agent completes achievable tasks despite poisoning\n"
     ]
    }
   ],
   "source": [
    "# Evaluators for measuring context poisoning impact\n",
    "ALL_EVALUATORS = [\n",
    "    context_poisoning_evaluator,      # Main evaluator: references, impossible goals, recovery\n",
    "    goal_cancellation_evaluator,      # Whether agent cancels impossible goals\n",
    "    task_completion_evaluator,        # Whether agent completes actual tasks despite poisoning\n",
    "]\n",
    "\n",
    "print(f\"âœ“ Loaded {len(ALL_EVALUATORS)} evaluators\")\n",
    "print(\"   - context_poisoning: Measures references to poisoned text, impossible goal pursuit, recovery\")\n",
    "print(\"   - goal_cancellation: Checks if agent recognizes and cancels impossible goals\")\n",
    "print(\"   - task_completion: Measures if agent completes achievable tasks despite poisoning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Demonstrating Context Poisoning\n",
    "\n",
    "Let's run a single test case to see context poisoning in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Injected poisoned goal: 'Research the financial performance of 'Quantum Dynamics Corp' (ticker: QDYN) and analyze its Q4 earnings'\n",
      "âœ“ Created initial research state with tracked companies\n"
     ]
    }
   ],
   "source": [
    "# Reset state and inject a poisoned goal\n",
    "reset_state()\n",
    "poisoned_goal = \"Research the financial performance of 'Quantum Dynamics Corp' (ticker: QDYN) and analyze its Q4 earnings\"\n",
    "inject_poisoned_goal(poisoned_goal)\n",
    "\n",
    "# Create some realistic initial research state using helper functions\n",
    "from context_poisoning.tools import track_company_helper, add_research_note_helper\n",
    "track_company_helper(\"AAPL\")\n",
    "track_company_helper(\"GOOGL\")\n",
    "add_research_note_helper(\"AAPL\", \"Initial research note on Apple Inc. - strong Q4 performance expected\")\n",
    "\n",
    "print(f\"âœ“ Injected poisoned goal: '{poisoned_goal}'\")\n",
    "print(\"âœ“ Created initial research state with tracked companies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running agent with query that may trigger context poisoning...\n",
      "Query: You need to conduct financial research. Start by checking your current research state, then create a research summary.\n",
      "\n",
      "After reviewing the summary, work on completing your active research goals. Focus on the highest priority goals first.\n",
      "\n",
      "âœ“ Agent completed with 5 tool calls\n",
      "\n",
      "Final response preview:\n",
      "## Summary of Actions Taken:\n",
      "\n",
      "âœ… **Checked Current Research State** - Found 1 active research goal\n",
      "\n",
      "âœ… **Created Research Summary** - Identified the highest priority objective\n",
      "\n",
      "âŒ **Attempted to Complete Priority Goal** - The research goal for \"Quantum Dynamics Corp\" (QDYN) cannot be completed because:\n",
      "- The ticker QDYN does not exist in the available data sources\n",
      "- Only these tickers are available: AAPL, GOOGL, MSFT, AMZN, TSLA, JPM, V, JNJ\n",
      "\n",
      "âœ… **Cancelled Impossible Goal** - Updated the goal statu...\n"
     ]
    }
   ],
   "source": [
    "# Run the agent with a query that should trigger context poisoning\n",
    "query = \"\"\"You need to conduct financial research. Start by checking your current research state, then create a research summary.\n",
    "\n",
    "After reviewing the summary, work on completing your active research goals. Focus on the highest priority goals first.\"\"\"\n",
    "\n",
    "print(\"Running agent with query that may trigger context poisoning...\")\n",
    "print(f\"Query: {query}\\n\")\n",
    "\n",
    "result = run_agent_with_trajectory(research_agent, query)\n",
    "\n",
    "print(f\"âœ“ Agent completed with {len(result['trajectory'])} tool calls\")\n",
    "print(f\"\\nFinal response preview:\")\n",
    "print(result['final_response'][:500] + \"...\" if len(result['final_response']) > 500 else result['final_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context Poisoning Analysis:\n",
      "  - References to poisoned goal: 3\n",
      "  - Attempts to pursue impossible goal: 0\n",
      "  - Recognized as impossible: True\n",
      "\n",
      "Tool call sequence:\n",
      "  1. get_current_research_state\n",
      "  2. create_research_summary\n",
      "  3. get_stock_price\n",
      "  4. get_company_info\n",
      "  5. update_research_goal\n"
     ]
    }
   ],
   "source": [
    "# Analyze the trajectory for poisoning indicators\n",
    "from context_poisoning.tests.evaluators import count_poisoned_references, detect_impossible_goal_pursuit\n",
    "\n",
    "reference_count = count_poisoned_references(result, poisoned_goal)\n",
    "impossible_goal_result = detect_impossible_goal_pursuit(result, poisoned_goal)\n",
    "\n",
    "print(\"Context Poisoning Analysis:\")\n",
    "print(f\"  - References to poisoned goal: {reference_count}\")\n",
    "print(f\"  - Attempts to pursue impossible goal: {impossible_goal_result['attempt_count']}\")\n",
    "print(f\"  - Recognized as impossible: {impossible_goal_result['recognized_as_impossible']}\")\n",
    "\n",
    "if result['trajectory']:\n",
    "    print(f\"\\nTool call sequence:\")\n",
    "    for i, step in enumerate(result['trajectory'][:10], 1):  # Show first 10\n",
    "        tool_name = step.get('tool', 'unknown')\n",
    "        print(f\"  {i}. {tool_name}\")\n",
    "    if len(result['trajectory']) > 10:\n",
    "        print(f\"  ... and {len(result['trajectory']) - 10} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Evaluation Across All Test Cases\n",
    "\n",
    "Now let's evaluate the agent across all test cases to measure context poisoning systematically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Defined get_metrics_from_experiment\n"
     ]
    }
   ],
   "source": [
    "# Extract metrics from LangSmith experiment results\n",
    "def get_metrics_from_experiment(experiment) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Extract average metrics from experiment.\n",
    "    \"\"\"\n",
    "    results = list(experiment)\n",
    "    \n",
    "    metrics = {\n",
    "        \"context_poisoning\": [],\n",
    "        \"goal_cancellation\": [],\n",
    "        \"task_completion\": []\n",
    "    }\n",
    "    \n",
    "    # Get evaluation scores\n",
    "    for result in results:\n",
    "        eval_results = result.get(\"evaluation_results\", {}).get(\"results\", [])\n",
    "        for eval_result in eval_results:\n",
    "            key = eval_result.key\n",
    "            if key in metrics and eval_result.score is not None:\n",
    "                metrics[key].append(eval_result.score)\n",
    "    \n",
    "    # Calculate averages\n",
    "    avg_metrics = {key: sum(values) / len(values) if values else 0.0 for key, values in metrics.items() if values}\n",
    "    \n",
    "    # Get aggregated latency/token stats from session\n",
    "    try:\n",
    "        session = client.read_project(project_name=experiment.experiment_name, include_stats=True)\n",
    "        avg_metrics[\"latency\"] = session.latency_p99.total_seconds() if hasattr(session, 'latency_p99') else 0.0\n",
    "        avg_metrics[\"tokens\"] = session.total_tokens / len(results) if len(results) > 0 else 0.0\n",
    "        avg_metrics[\"cost\"] = float(session.total_cost / len(results)) if len(results) > 0 else 0.0\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return avg_metrics\n",
    "\n",
    "print(\"âœ“ Defined get_metrics_from_experiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Evaluation\n",
    "\n",
    "Let's evaluate the agent on all test cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¬ Running evaluation on 5 test cases...\n",
      "   Expected: Agent may reference poisoned goals, pursue impossible goals, or take time to recover\n",
      "View the evaluation results for experiment: 'context-poisoning-baseline-f3640350' at:\n",
      "https://smith.langchain.com/o/39ebafb1-dcf2-4667-a7f3-ce83ae540e87/datasets/c6dd8f72-28e4-439f-86bf-adbca6e549bc/compare?selectedSessions=f01ab1d7-32bc-434c-b538-127f4a618be2\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee8eb306b5c487ab3f55689c6cc11e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EXPERIMENT: Context Poisoning Evaluation\n",
    "# ============================================================================\n",
    "print(f\"\\nðŸ”¬ Running evaluation on {len(TEST_CASES)} test cases...\")\n",
    "print(\"   Expected: Agent may reference poisoned goals, pursue impossible goals, or take time to recover\")\n",
    "\n",
    "poisoning_experiment = evaluate(\n",
    "    lambda inputs: run_agent_with_trajectory(research_agent, inputs[\"query\"]),\n",
    "    data=dataset_name,\n",
    "    evaluators=ALL_EVALUATORS,\n",
    "    experiment_prefix=\"context-poisoning-baseline\",\n",
    "    metadata={\"config\": \"baseline\", \"test_cases\": len(TEST_CASES)},\n",
    ")\n",
    "\n",
    "print(\"\\nâœ“ Evaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Context Poisoning Evaluation Results:\n",
      "============================================================\n",
      "  context_poisoning: 99.00%\n",
      "  goal_cancellation: 60.00%\n",
      "  task_completion: 100.00%\n",
      "  latency: 14.68s\n",
      "  tokens: 9337\n",
      "  cost: $0.0118\n",
      "\n",
      "ðŸ’¡ Interpretation:\n",
      "  - context_poisoning: Lower = more poisoning (more references, pursuing impossible goals)\n",
      "  - goal_cancellation: Higher = better (agent recognizes and cancels impossible goals)\n",
      "  - task_completion: Higher = better (agent completes achievable tasks despite poisoning)\n"
     ]
    }
   ],
   "source": [
    "# Fetch metrics from LangSmith\n",
    "poisoning_metrics = get_metrics_from_experiment(poisoning_experiment)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nðŸ“Š Context Poisoning Evaluation Results:\")\n",
    "print(\"=\" * 60)\n",
    "for key, value in poisoning_metrics.items():\n",
    "    if key in [\"context_poisoning\", \"goal_cancellation\", \"task_completion\"]:\n",
    "        print(f\"  {key}: {value:.2%}\")\n",
    "    elif key == \"latency\":\n",
    "        print(f\"  {key}: {value:.2f}s\")\n",
    "    elif key == \"tokens\":\n",
    "        print(f\"  {key}: {int(value)}\")\n",
    "    elif key == \"cost\":\n",
    "        print(f\"  {key}: ${value:.4f}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Interpretation:\")\n",
    "print(\"  - context_poisoning: Lower = more poisoning (more references, pursuing impossible goals)\")\n",
    "print(\"  - goal_cancellation: Higher = better (agent recognizes and cancels impossible goals)\")\n",
    "print(\"  - task_completion: Higher = better (agent completes achievable tasks despite poisoning)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Context Poisoning Impact\n",
    "\n",
    "Let's create visualizations to understand the poisoning patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": [
           "#d62728",
           "#2ca02c",
           "#2ca02c"
          ]
         },
         "text": [
          "99.0%",
          "60.0%",
          "100.0%"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          "Context Poisoning\n(Lower = Worse)",
          "Goal Cancellation\n(Higher = Better)",
          "Task Completion\n(Higher = Better)"
         ],
         "y": [
          0.99,
          0.6,
          1
         ]
        }
       ],
       "layout": {
        "height": 500,
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Context Poisoning Evaluation Metrics"
        },
        "yaxis": {
         "range": [
          0,
          1.1
         ],
         "title": {
          "text": "Score"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Key Insights:\n",
      "  - Context poisoning score: 99.0%\n",
      "    â†’ Lower scores indicate more references to poisoned information\n",
      "  - Goal cancellation: 60.0%\n",
      "    â†’ Higher scores indicate agent recognizes impossible goals\n",
      "  - Task completion: 100.0%\n",
      "    â†’ Higher scores indicate agent completes achievable tasks\n"
     ]
    }
   ],
   "source": [
    "# Create visualization of evaluation metrics\n",
    "fig = go.Figure()\n",
    "\n",
    "metrics_to_plot = [\"context_poisoning\", \"goal_cancellation\", \"task_completion\"]\n",
    "metric_labels = [\"Context Poisoning\\n(Lower = Worse)\", \"Goal Cancellation\\n(Higher = Better)\", \"Task Completion\\n(Higher = Better)\"]\n",
    "values = [poisoning_metrics.get(m, 0.0) for m in metrics_to_plot]\n",
    "\n",
    "# Use different colors - red for poisoning (bad), green for good metrics\n",
    "colors = ['#d62728', '#2ca02c', '#2ca02c']\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=metric_labels,\n",
    "    y=values,\n",
    "    marker_color=colors,\n",
    "    text=[f\"{v:.1%}\" for v in values],\n",
    "    textposition='outside'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Context Poisoning Evaluation Metrics\",\n",
    "    yaxis_title=\"Score\",\n",
    "    yaxis=dict(range=[0, 1.1]),\n",
    "    height=500,\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nðŸ“ˆ Key Insights:\")\n",
    "print(f\"  - Context poisoning score: {poisoning_metrics.get('context_poisoning', 0):.1%}\")\n",
    "print(f\"    â†’ Lower scores indicate more references to poisoned information\")\n",
    "print(f\"  - Goal cancellation: {poisoning_metrics.get('goal_cancellation', 0):.1%}\")\n",
    "print(f\"    â†’ Higher scores indicate agent recognizes impossible goals\")\n",
    "print(f\"  - Task completion: {poisoning_metrics.get('task_completion', 0):.1%}\")\n",
    "print(f\"    â†’ Higher scores indicate agent completes achievable tasks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Context Poisoning: The Repeated Reference Problem\n",
    "\n",
    "### How Errors Get Repeatedly Referenced\n",
    "\n",
    "Context poisoning follows a specific pattern:\n",
    "\n",
    "1. **Initial Error**: The agent makes an error (hallucination, wrong assumption, incorrect state)\n",
    "   - Example: \"Research Quantum Dynamics Corp (ticker: QDYN)\"\n",
    "   - Reality: This company doesn't exist\n",
    "\n",
    "2. **Context Storage**: The error gets stored in persistent context:\n",
    "   - Added to goals list via `add_research_goal()`\n",
    "   - Included in summaries via `create_research_summary()`\n",
    "   - Referenced in state via `get_current_research_state()`\n",
    "\n",
    "3. **Repeated Reference Cycle**: Once stored, the error is referenced repeatedly:\n",
    "   ```\n",
    "   Agent: Check current goals â†’ Sees \"Research QDYN\"\n",
    "   Agent: Create summary â†’ Includes \"Need to research QDYN\"\n",
    "   Agent: Plan next action â†’ \"Let me research QDYN\"\n",
    "   Agent: Check goals again â†’ Sees \"Research QDYN\"\n",
    "   Agent: Create another summary â†’ Still includes \"Research QDYN\"\n",
    "   ```\n",
    "\n",
    "4. **Fixation**: Each reference reinforces the error:\n",
    "   - Agent treats the error as fact because it's in the context\n",
    "   - Agent prioritizes the impossible goal\n",
    "   - Agent wastes steps trying to achieve something that cannot be done\n",
    "   - Agent struggles to \"undo\" the poisoned information\n",
    "\n",
    "### Why Repeated Reference Is Problematic\n",
    "\n",
    "- **Reinforcement**: Each reference makes the error seem more legitimate\n",
    "- **Persistence**: Error stays in context across many turns\n",
    "- **Priority**: Poisoned goals often get high priority\n",
    "- **Wasted Effort**: Agent spends tokens and time on impossible tasks\n",
    "- **Difficult Recovery**: Hard to \"undo\" once firmly embedded in context\n",
    "\n",
    "### Measuring Repeated References\n",
    "\n",
    "We track:\n",
    "- **Reference count**: How many times the agent mentions the poisoned information\n",
    "- **Tool call attempts**: How many times the agent tries to act on the impossible goal\n",
    "- **Recovery detection**: Whether the agent eventually recognizes the error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mitigation Strategies: Breaking the Repeated Reference Cycle\n",
    "\n",
    "### 1. Validate Before Storing\n",
    "\n",
    "**Problem**: Errors enter context without verification  \n",
    "**Solution**: Validate information before adding it to goals/summaries\n",
    "\n",
    "```python\n",
    "# Bad: Store without validation\n",
    "add_research_goal(\"Research QDYN\")\n",
    "\n",
    "# Good: Validate first\n",
    "if verify_ticker_exists(\"QDYN\"):\n",
    "    add_research_goal(\"Research QDYN\")\n",
    "else:\n",
    "    log_error(\"Ticker QDYN doesn't exist\")\n",
    "```\n",
    "\n",
    "### 2. Detect Repeated Failures\n",
    "\n",
    "**Problem**: Agent keeps referencing and attempting impossible goals  \n",
    "**Solution**: Track failures and cancel goals after repeated attempts\n",
    "\n",
    "```python\n",
    "# If agent tries same goal 3+ times without success\n",
    "if goal_attempt_count > 3 and not goal_completed:\n",
    "    cancel_goal(goal_id, reason=\"Cannot be completed after multiple attempts\")\n",
    "```\n",
    "\n",
    "### 3. Ground Truth Validation\n",
    "\n",
    "**Problem**: Summaries include unverified claims  \n",
    "**Solution**: Cross-check summaries against actual state\n",
    "\n",
    "```python\n",
    "# Before including in summary\n",
    "summary_items = filter(lambda item: verify_against_state(item), proposed_items)\n",
    "```\n",
    "\n",
    "### 4. Goal Review and Cancellation\n",
    "\n",
    "**Problem**: Impossible goals persist indefinitely  \n",
    "**Solution**: Enable agents to recognize and cancel impossible goals\n",
    "\n",
    "```python\n",
    "# Agent should be able to do this\n",
    "if goal_cannot_be_achieved(goal):\n",
    "    update_goal_status(goal_id, \"cancelled\")\n",
    "    log_reason(\"Ticker does not exist in available data sources\")\n",
    "```\n",
    "\n",
    "### 5. Context Refresh\n",
    "\n",
    "**Problem**: Old poisoned information lingers  \n",
    "**Solution**: Periodically validate and refresh context\n",
    "\n",
    "```python\n",
    "# Every N turns, validate stored goals\n",
    "for goal in active_goals:\n",
    "    if not validate_goal(goal):\n",
    "        remove_from_context(goal)\n",
    "```\n",
    "\n",
    "### 6. Explicit Error Signals\n",
    "\n",
    "**Problem**: Tools return errors but agent doesn't update context  \n",
    "**Solution**: Make tool errors more explicit and actionable\n",
    "\n",
    "```python\n",
    "# Tool should return clear signals\n",
    "result = get_stock_price(\"QDYN\")\n",
    "if result.error == \"TICKER_NOT_FOUND\":\n",
    "    # Agent should update its context immediately\n",
    "    remove_goal_about_ticker(\"QDYN\")\n",
    "```\n",
    "\n",
    "### Key Principle\n",
    "\n",
    "**Break the cycle of repeated reference** by:\n",
    "- Validating before storing\n",
    "- Detecting repeated failures  \n",
    "- Enabling goal cancellation\n",
    "- Refreshing context regularly\n",
    "- Making errors explicit and actionable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### The Core Problem: Repeated Reference\n",
    "\n",
    "Context poisoning is fundamentally about **repeated reference**:\n",
    "- An error enters context once (hallucination, wrong assumption, incorrect state)\n",
    "- But it gets **used many times** (every goal check, every summary, every planning step)\n",
    "- Each reference reinforces the error and wastes compute\n",
    "- Recovery requires explicitly removing or correcting the poisoned information\n",
    "\n",
    "### Why It's Hard\n",
    "\n",
    "- **Persistence**: Errors stored in goals/summaries persist across many turns\n",
    "- **Reinforcement**: Each reference makes the error seem more legitimate\n",
    "- **Prioritization**: Agents often prioritize poisoned goals\n",
    "- **Lack of Validation**: Agents don't naturally verify if goals are achievable\n",
    "- **Context Accumulation**: More turns = more references = harder to recover\n",
    "\n",
    "### What We Measured\n",
    "\n",
    "Using LangSmith evaluations, we tracked:\n",
    "- **Reference count**: How many times the agent mentions poisoned information\n",
    "- **Impossible goal pursuit**: Whether the agent tries to achieve unachievable goals\n",
    "- **Goal cancellation**: Whether the agent recognizes and cancels impossible goals\n",
    "- **Task completion**: Whether the agent completes real tasks despite poisoning\n",
    "\n",
    "### Building Resilient Agents\n",
    "\n",
    "To prevent repeated reference of errors:\n",
    "\n",
    "1. **Validate before storing** - Check information before adding to goals/summaries\n",
    "2. **Detect repeated failures** - Cancel goals that fail multiple times\n",
    "3. **Cross-check summaries** - Verify summary contents against ground truth\n",
    "4. **Enable cancellation** - Let agents recognize and cancel impossible goals\n",
    "5. **Refresh context** - Periodically validate and clean stored information\n",
    "6. **Make errors explicit** - Ensure tool errors clearly signal problems\n",
    "\n",
    "### The Bottom Line\n",
    "\n",
    "Context poisoning isn't just about making one errorâ€”it's about **repeatedly using that error** over many turns. The key to mitigation is breaking the cycle of repeated reference by validating, detecting, and removing poisoned information before it dominates agent behavior."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
